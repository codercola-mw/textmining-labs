# textmining-labs
python

l1:  Information retrieval

In this lab we applied basic techniques from information retrieval to implement the core of a
minimalistic search engine. The data for this lab consists of a collection of app descriptions
scraped from the Google Play Store. From this collection, our search engine should retrieve
those apps whose descriptions best match a given query under the vector space model.

l2: Text classification

Text classification is the task of sorting text documents into predefined classes. The concrete
problem we worked on in this lab is the classification of texts with respect to their
political affiliation.

L3: Text clustering and topic modelling

In this lab we experiment with both hard and soft clustering techniques. In the first part we used the k-means algorithm, 
and in the second part, we used a
topic model based on the Latent Dirichlet Allocation (LDA).

L4: Word embeddings

In this lab we explore word embeddings. A word embedding is a mapping of words to
points in a vector space such that nearby words (points) are similar in terms of their distributional
properties. We used word embedding to find similar words, and evaluate their usefulness in
an inference task. The word vectors that come with spaCy. 

L5: Information extraction

Information extraction (IE) is the task of identifying named entities and semantic relations
between these entities in text data. In this lab we will focus on two sub-tasks in IE, named entity
recognition (identifying mentions of entities) and entity linking (matching these mentions to
entities in a knowledge base).





